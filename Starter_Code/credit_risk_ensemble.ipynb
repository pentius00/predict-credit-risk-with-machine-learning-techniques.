{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' in this study we are analysing loan data to determine who is in risk of default their loan,\n",
    "after cleaning the data set and balancig the scaled fetures, we introduce our train features to train and we take the diferent metrics\n",
    "to get our results using the random forest classifier and the easy ensable classifier'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                     float64\n",
       "int_rate                      float64\n",
       "installment                   float64\n",
       "home_ownership                 object\n",
       "annual_inc                    float64\n",
       "                               ...   \n",
       "total_bal_ex_mort             float64\n",
       "total_bc_limit                float64\n",
       "total_il_high_credit_limit    float64\n",
       "hardship_flag                  object\n",
       "debt_settlement_flag           object\n",
       "Length: 86, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('Resources/LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the data\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "x_cols = [i for i in df.columns if i not in ('hardship_flag', 'debt_settlement_flag','home_ownership', 'verification_status', 'issue_d', 'pymnt_plan', 'loan_status')]\n",
    "\n",
    "\n",
    "X = df[x_cols].dropna()\n",
    "\n",
    "# Create our target\n",
    "y = df['loan_status']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                     float64\n",
       "int_rate                      float64\n",
       "installment                   float64\n",
       "annual_inc                    float64\n",
       "dti                           float64\n",
       "                               ...   \n",
       "tax_liens                     float64\n",
       "tot_hi_cred_lim               float64\n",
       "total_bal_ex_mort             float64\n",
       "total_bc_limit                float64\n",
       "total_il_high_credit_limit    float64\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of records in the training dataset is: 55053\n",
      "the number of records in the test dataset is 13764\n",
      "the number of records in the y_train dataset is: 55053\n"
     ]
    }
   ],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "le = preprocessing.LabelEncoder()\n",
    "X = X.apply(le.fit_transform)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "#check the number of records \n",
    "print(f\"the number of records in the training dataset is:\", X_train.shape[0])\n",
    "print(f\"the number of records in the test dataset is\", X_test.shape[0])\n",
    "print(f\"the number of records in the y_train dataset is:\", y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learners\n",
    "\n",
    "In this section, you will compare two ensemble algorithms to determine which algorithm results in the best performance. You will train a Balanced Random Forest Classifier and an Easy Ensemble classifier . For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. Train the model using the training data. \n",
    "2. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "3. Display the confusion matrix from sklearn.metrics.\n",
    "4. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "5. For the Balanced Random Forest Classifier only, print the feature importance sorted in descending order (most important feature to least important) along with the feature score\n",
    "\n",
    "Note: Use a random state of 1 for each algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "#check the model performance\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "\n",
    "\n",
    "bac = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"balance accuracy :\", bac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "recall = tp /(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confusion matrix\")\n",
    "display(cm_df)\n",
    "print(F\"the recall| of this model is:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.sort_values(by=, axis=0, ascending=True)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier\n",
    "\n",
    "\n",
    "eec = EasyEnsembleClassifier(random_state=1)\n",
    "eec_model = eec.fit(X_train, y_train)\n",
    "y_pred= eec_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(F\"the recall of this model is:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Final Questions\n",
    "\n",
    "1. Which model had the best balanced accuracy score?\n",
    "\n",
    "    the same recall score\n",
    "    \n",
    "2. Which model had the best recall score?\n",
    "\n",
    "  the same recall score\n",
    "\n",
    "3. Which model had the best geometric mean score?\n",
    "\n",
    "    Easy Ensemble Classifier\n",
    "\n",
    "4. What are the top three features?\n",
    "\n",
    "    YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
